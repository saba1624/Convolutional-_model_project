#Import packages
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets


#Normalization
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])

trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle = True)
testLoader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle = False)

#Neural network architecture, hyperparameter tuning and forward propagation
class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()
    self.conv1 = nn.Conv2d(3, 32, kernel_size = 3, padding=1)
    self.relu = nn.ReLU()
    self.maxpool = nn.MaxPool2d(kernel_size=2, stride = 2 )
    self.conv2 = nn.Conv2d(32, 10, kernel_size=3, padding=1)
    self.fc = nn.Linear(10 * 8 * 8, 10)

  def forward(self, x):
    x = self.relu(self.conv1(x))
    x = self.maxpool(x)
    x = self.relu(self.conv2(x))
    x = self.maxpool(x)
    x = x.view(x.size(0), -1)
    x = self.fc(x)
    return x

model = Net()


# GPU activation, backpropagation hyperparameters
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


# Number of Epochs
num_epochs = 5

# Training cycle.
for epoch in range(num_epochs):
    running_loss = 0.0
    for i, (inputs, labels) in enumerate(trainloader):
        # Put data on (CPU o GPU)
        inputs = inputs.to(device)
        labels = labels.to(device)

        
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # Backward pass y optimizaci√≥n
        loss.backward()
        optimizer.step()

        # AVG Loss on epoch
        running_loss += loss.item()
        if i % 200 == 199:
            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 200:.3f}')
            running_loss = 0.0

print('training is over.')

